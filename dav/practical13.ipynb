{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab4dbcc",
   "metadata": {},
   "source": [
    "# Logistic Regression Model for Iris Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e59018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For model training and evaluation\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78572875",
   "metadata": {},
   "source": [
    "## Load and Explore the Iris Dataset\n",
    "\n",
    "Load the Iris dataset using sklearn's datasets module and explore its structure, including feature names and target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "020aa61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target target_name  \n",
      "0       0      setosa  \n",
      "1       0      setosa  \n",
      "2       0      setosa  \n",
      "3       0      setosa  \n",
      "4       0      setosa  \n"
     ]
    }
   ],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "\n",
    "# Map target names for better understanding\n",
    "target_names = {i: name for i, name in enumerate(iris.target_names)}\n",
    "iris_df['target_name'] = iris_df['target'].map(target_names)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(iris_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf67cd",
   "metadata": {},
   "source": [
    "## Split the Dataset into Training and Testing Sets\n",
    "\n",
    "Use train_test_split from sklearn to divide the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4609869b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (105, 4)\n",
      "X_test shape: (45, 4)\n",
      "y_train shape: (105,)\n",
      "y_test shape: (45,)\n",
      "\n",
      "Class distribution in y:\n",
      "[50 50 50]\n",
      "\n",
      "Class distribution in y_train:\n",
      "[35 35 35]\n",
      "\n",
      "Class distribution in y_test:\n",
      "[15 15 15]\n"
     ]
    }
   ],
   "source": [
    "# Define features X and target y\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training (70%) and testing (30%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Check the shape of training and testing sets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Confirm that the class distribution is maintained in both sets\n",
    "print(\"\\nClass distribution in y:\")\n",
    "print(np.bincount(y))\n",
    "\n",
    "print(\"\\nClass distribution in y_train:\")\n",
    "print(np.bincount(y_train))\n",
    "\n",
    "print(\"\\nClass distribution in y_test:\")\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b92d7e7",
   "metadata": {},
   "source": [
    "## Train a Logistic Regression Model\n",
    "\n",
    "Use sklearn's LogisticRegression to train a model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4eb5746e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficients:\n",
      "sepal length (cm): [-0.54508414  0.42116822  0.12391592]\n",
      "sepal width (cm): [ 0.76445112 -0.42711735 -0.33733377]\n",
      "petal length (cm): [-2.22894098 -0.10046531  2.32940629]\n",
      "petal width (cm): [-0.97457748 -0.83878104  1.81335852]\n",
      "\n",
      "Intercept values:\n",
      "[  9.92774954   2.42287865 -12.35062819]\n",
      "\n",
      "Probability estimates for first 5 training samples:\n",
      "Sample 1: [0.27254453 0.72538322 0.00207225] (Actual class: 1)\n",
      "Sample 2: [0.00288155 0.81615596 0.18096249] (Actual class: 1)\n",
      "Sample 3: [9.79597444e-01 2.04023506e-02 2.05058225e-07] (Actual class: 0)\n",
      "Sample 4: [5.72254040e-06 1.92906759e-02 9.80703602e-01] (Actual class: 2)\n",
      "Sample 5: [0.02587304 0.9186112  0.05551576] (Actual class: 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the logistic regression model\n",
    "# Using 'multinomial' solver because we have more than 2 classes\n",
    "logistic_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Print the model coefficients\n",
    "print(\"Model coefficients:\")\n",
    "for i, feature_name in enumerate(iris.feature_names):\n",
    "    print(f\"{feature_name}: {logistic_model.coef_[:, i]}\")\n",
    "\n",
    "print(\"\\nIntercept values:\")\n",
    "print(logistic_model.intercept_)\n",
    "\n",
    "# Get the probability estimates for training data\n",
    "y_train_proba = logistic_model.predict_proba(X_train)\n",
    "\n",
    "# Print probability estimates for first 5 samples\n",
    "print(\"\\nProbability estimates for first 5 training samples:\")\n",
    "for i in range(5):\n",
    "    print(f\"Sample {i+1}: {y_train_proba[i]} (Actual class: {y_train[i]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83de7db",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "\n",
    "Use the trained model to make predictions on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46549c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 predictions:\n",
      "       Actual   Predicted\n",
      "0   virginica   virginica\n",
      "1  versicolor  versicolor\n",
      "2   virginica  versicolor\n",
      "3  versicolor  versicolor\n",
      "4   virginica   virginica\n",
      "5   virginica   virginica\n",
      "6  versicolor  versicolor\n",
      "7  versicolor  versicolor\n",
      "8      setosa      setosa\n",
      "9   virginica   virginica\n",
      "\n",
      "Correct predictions: 42 (93.33%)\n",
      "Incorrect predictions: 3 (6.67%)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Get probability estimates for test data\n",
    "y_test_proba = logistic_model.predict_proba(X_test)\n",
    "\n",
    "# Create a DataFrame to compare actual vs predicted values\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': [iris.target_names[i] for i in y_test],\n",
    "    'Predicted': [iris.target_names[i] for i in y_pred]\n",
    "})\n",
    "\n",
    "# Display the first 10 predictions\n",
    "print(\"First 10 predictions:\")\n",
    "print(results_df.head(10))\n",
    "\n",
    "# Count the number of correct and incorrect predictions\n",
    "correct = (y_test == y_pred).sum()\n",
    "incorrect = (y_test != y_pred).sum()\n",
    "total = len(y_test)\n",
    "\n",
    "print(f\"\\nCorrect predictions: {correct} ({correct/total*100:.2f}%)\")\n",
    "print(f\"Incorrect predictions: {incorrect} ({incorrect/total*100:.2f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ea33e",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "\n",
    "Calculate and display metrics such as accuracy, precision_score, recall_score, and f1_score using sklearn's metrics module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06cfade7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Metrics:\n",
      "Accuracy: 0.9333\n",
      "Precision: 0.9345\n",
      "Recall: 0.9333\n",
      "F1 Score: 0.9333\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       0.88      0.93      0.90        15\n",
      "   virginica       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.93      0.93        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Display the metrics\n",
    "print(\"Model Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Generate a classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
